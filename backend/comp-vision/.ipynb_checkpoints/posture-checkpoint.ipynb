{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "86e6380b-dbea-4e94-9a91-032e6601dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "# import csv\n",
    "import numpy as np\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "945212ac-8f6a-4d81-9c39-90f14e5fea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2a29481-114f-413f-9ec1-dd583218016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "    \n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         # image.flags.writable = False\n",
    "\n",
    "#         results = pose.process(image)\n",
    "\n",
    "#         # image.flags.writable = True\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "#         cv2.imshow('Mediapipe feed', image)\n",
    "        \n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dac1574-6c0e-43ae-911f-bb0987cc3fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({(15, 21), (16, 20), (18, 20), (3, 7), (14, 16), (23, 25), (28, 30), (11, 23), (27, 31), (6, 8), (15, 17), (24, 26), (16, 22), (4, 5), (5, 6), (29, 31), (12, 24), (23, 24), (0, 1), (9, 10), (1, 2), (0, 4), (11, 13), (30, 32), (28, 32), (15, 19), (16, 18), (25, 27), (26, 28), (12, 14), (17, 19), (2, 3), (11, 12), (27, 29), (13, 15)})\n"
     ]
    }
   ],
   "source": [
    "print(mp_pose.POSE_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4739a450-0604-4863-9309-1f68fe383d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({(15, 21), (16, 20), (18, 20), (3, 7), (14, 16), (23, 25), (28, 30), (11, 23), (27, 31), (6, 8), (15, 17), (24, 26), (16, 22), (4, 5), (5, 6), (29, 31), (12, 24), (23, 24), (0, 1), (9, 10), (1, 2), (0, 4), (11, 13), (30, 32), (28, 32), (15, 19), (16, 18), (25, 27), (26, 28), (12, 14), (17, 19), (2, 3), (11, 12), (27, 29), (13, 15)})\n"
     ]
    }
   ],
   "source": [
    "print(mp.solutions.pose.POSE_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d3a6bc-7d36-44c8-adc8-075081a97ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def body_in_frame(landmarks):\n",
    "    left = landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].y\n",
    "    right = landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].y\n",
    "    nose = landmarks[mp_pose.PoseLandmark.NOSE.value].y\n",
    "\n",
    "    # heel out of frame\n",
    "    if left > 0.95 or right > 0.95:\n",
    "        return False\n",
    "    # heel wayy to in frame\n",
    "    if left < 0 or right < 0 or nose < 0:\n",
    "        return False\n",
    "    if nose > 0.15:\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3930ebf0-6d14-4892-9f8c-ba265fffb18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1712448763.557816   54305 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1712448763.598070   54807 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 545.23.08), renderer: NVIDIA GeForce RTX 2060/PCIe/SSE2\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "captured_body = False\n",
    "quit = False\n",
    "measurements = []\n",
    "start = None\n",
    "image = None\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "    \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # variables to maintain continous stream of data\n",
    "            if not captured_body:\n",
    "                captured_body = True\n",
    "                start = time.time() \n",
    "\n",
    "            # if our body isn't in frame, restart\n",
    "            if not body_in_frame(landmarks):\n",
    "                captured_body = False\n",
    "                start = None\n",
    "                measurements.clear()\n",
    "                \n",
    "            # add landmarks to our current stuff\n",
    "            if captured_body:\n",
    "                measurements.append(landmarks)\n",
    "                \n",
    "                # quit when we have 3 seconds of data\n",
    "                if time.time() - start > 3:\n",
    "                    quit = True\n",
    "            \n",
    "        except:\n",
    "            captured_body = False\n",
    "            start = None\n",
    "            measurements.clear()\n",
    "\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        cv2.imshow('Mediapipe feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q') or quit:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159e1688-ee71-4d64-8b34-36492a8ba1c7",
   "metadata": {},
   "source": [
    "## Turn measurements into a 3d tensor. \n",
    "The tensor should be of shape(`len(measurements)`, `33` (the number of landmarks), `4` (x, y, z, and visisibility))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5d38bd27-48a6-4d2d-9331-fe9120b24cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29, 33, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor_data = torch.zeros(len(measurements), 33, 4)\n",
    "print(tensor_data.shape)\n",
    "\n",
    "for idx, itm in enumerate(measurements):\n",
    "    for jdx, jtm in enumerate(itm):\n",
    "        tensor_data[idx][jdx][0] = jtm.x\n",
    "        tensor_data[idx][jdx][1] = jtm.y\n",
    "        tensor_data[idx][jdx][2] = jtm.z\n",
    "        tensor_data[idx][jdx][3] = jtm.visibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b63772-5f21-4375-9fc4-99507da060fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2f50debb-be74-4f85-a482-4e40aa76855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lndmrk in mp_pose.PoseLandmark:\n",
    "#     print(lndmrk.name, \":\",  lndmrk.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52221312-c05d-44fe-8a10-9cc382bb9d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d98c39d1-61f4-4555-9020-1a3c5f7dffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_foot = landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].y\n",
    "# right_foot = landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].y\n",
    "# nose = landmarks[mp_pose.PoseLandmark.NOSE.value].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7add7097-ac9f-40c6-81df-eccc24a64e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(nose)\n",
    "# print(right_foot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b560a8d-c926-42df-87ec-897ac9fcea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((left_foot + right_foot)/2 - nose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d743e-fe42-46eb-b3d5-aef3290bee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('BGR Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e949f596-7d87-46f9-993f-d0618f245957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_avg, right_avg, nose_avg = [], [], []\n",
    "\n",
    "# for m in measurements:\n",
    "#     left_avg.append(m[mp_pose.PoseLandmark.LEFT_HEEL.value].y)\n",
    "#     right_avg.append(m[mp_pose.PoseLandmark.RIGHT_HEEL.value].y)\n",
    "#     nose_avg.append(m[mp_pose.PoseLandmark.NOSE.value].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d95fdc93-dce5-45de-8864-518cc0df3c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sum(left_avg)/len(left_avg) - sum(nose_avg)/len(nose_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "18a40780-5ebc-43fc-aba6-7126732c4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_avg_x(measurements, i):\n",
    "    sum = 0    \n",
    "    for m in measurements:\n",
    "        sum += m[i].x\n",
    "    return sum / len(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "67d15a22-3f64-4bb4-930c-cfac604e81f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_avg_y(measurements, i):\n",
    "    sum = 0    \n",
    "    for m in measurements:\n",
    "        sum += m[i].y\n",
    "    return sum / len(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16ebe364-7802-4981-a7f2-c7822bbe7647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# shldr, elb, wrst are lists of NormalizedLandmark (x,y,z)\n",
    "def find_sleeve_length(shldr, elb, wrst):\n",
    "    # print(type(shldr[0]))\n",
    "    shldr_x = find_avg_x(shldr)\n",
    "    shldr_y = find_avg_y(shldr)\n",
    "    elb_x = find_avg_x(elb)\n",
    "    elb_y = find_avg_x(elb)\n",
    "    wrst_x = find_avg_x(wrst)\n",
    "    wrst_y = find_avg_y(wrst)\n",
    "\n",
    "    d1 = math.sqrt((elb_x - shldr_x)**2 + (elb_y - shldr_y)**2)\n",
    "    d2 = math.sqrt((elb_x - wrst_x)**2 + (elb_y - wrst_y)**2)\n",
    "    \n",
    "    return d1 + d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "719999aa-5f82-4b4c-879b-9f940d3c7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sleeve(measurements):\n",
    "    # all these lists should be lists of x,y,z,visibility objects\n",
    "    r_shldr, r_elb, r_wrst = [], [], []\n",
    "    l_shldr, l_elb, l_wrst = [], [], [] \n",
    "\n",
    "    for m in measurements:\n",
    "        r_shldr.append(m[mp_pose.PoseLandmark.RIGHT_SHOULDER.value])\n",
    "        r_elb.append(m[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "        r_wrst.append(m[mp_pose.PoseLandmark.RIGHT_WRIST.value])\n",
    "        l_shldr.append(m[mp_pose.PoseLandmark.LEFT_SHOULDER.value])\n",
    "        l_elb.append(m[mp_pose.PoseLandmark.LEFT_ELBOW.value])\n",
    "        l_wrst.append(m[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "    \n",
    "    r_arm = find_sleeve_length(r_shldr, r_elb, r_wrst)\n",
    "    print(r_arm)\n",
    "    l_arm = find_sleeve_length(l_shldr, l_elb, l_wrst)\n",
    "    print(l_arm)\n",
    "    return (l_arm + r_arm) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d80a9-8c89-44f2-877d-603723061bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "298f0a39-e863-4434-bfaa-0cb434c0c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bottom(r_heel, l_heel):\n",
    "    l_heel_x = find_avg_x(l_heel)\n",
    "    l_heel_y = find_avg_y(l_heel)\n",
    "    r_heel_x = find_avg_x(r_heel)\n",
    "    r_heel_y = find_avg_y(r_heel)\n",
    "\n",
    "    avg_x = (l_heel_x + r_heel_x)/2\n",
    "    avg_y = (l_heel_y + r_heel_y)/2\n",
    "    return (avg_x, avg_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2123be60-2a51-4579-92a9-87637425a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top(nose):\n",
    "    nose_avg_x = find_avg_x(nose)\n",
    "    nose_avg_y = find_avg_y(nose)\n",
    "    return (nose_avg_x, nose_avg_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72c29cba-325d-4530-a8b6-a9c1a5e4ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_height(measurements):\n",
    "    r_heel, l_heel, nose = [], [], []\n",
    "    \n",
    "    for m in measurements:\n",
    "        r_heel.append(m[mp_pose.PoseLandmark.RIGHT_HEEL.value])\n",
    "        l_heel.append(m[mp_pose.PoseLandmark.LEFT_HEEL.value])\n",
    "        nose.append(m[mp_pose.PoseLandmark.NOSE.value])\n",
    "\n",
    "    # returns tuple of (avg_x_bottom, avg_y_bottom)\n",
    "    bot = find_bottom(r_heel, l_heel)\n",
    "    top = find_top(nose)\n",
    "    \n",
    "    return math.sqrt((bot[0] - top[0])**2 + (bot[1] - top[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c73da86d-426a-45b0-85b4-362e8fda908e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_pose.PoseLandmark.RIGHT_SHOULDER.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d2aab298-3fbc-4747-8994-c4dde91c3e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "22e74254-f5c0-433f-b1aa-b8b1f2940ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49440450188531315\n",
      "0.989862869307505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7421336855964091"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_sleeve(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "073d439e-f28e-4fa0-845e-d092b5f78648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7097005745531846"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_height(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd562cba-a38d-4e06-a453-5fc5073abac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5382372868833368\n",
      "1.1235459328775974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76.81518395448487"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(height - 5) / find_height(measurements) * find_sleeve(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0dcf9db3-6048-4c33-a752-3c942fffbfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_between_two(measurements, pair):\n",
    "    i1_x = find_avg_x(measurements, pair[0])\n",
    "    i1_y = find_avg_y(measurements, pair[0])\n",
    "    i2_x = find_avg_x(measurements, pair[1])\n",
    "    i2_y = find_avg_y(measurements, pair[1])\n",
    "\n",
    "    return math.sqrt((i1_x - i2_x)**2 + (i1_y - i2_y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "66e98255-3e29-492f-9ced-cfdb7ff5396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(measurements, landmarks):\n",
    "    distance = 0\n",
    "    \n",
    "    for i in range(len(landmarks) - 1):  # Iterate up to the second last element\n",
    "        pair = (landmarks[i], landmarks[i+1])  # Access current element and the next one\n",
    "        # print(pair)\n",
    "        distance += get_distance_between_two(measurements, pair)\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e83f4245-5a04-4aa2-9afa-e8f3a0d767b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_inseam(measurements):\n",
    "    d1 = get_distance(measurements, [mp_pose.PoseLandmark.LEFT_HIP.value, mp_pose.PoseLandmark.LEFT_KNEE.value, mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "    d2 = get_distance(measurements, [mp_pose.PoseLandmark.RIGHT_HIP.value, mp_pose.PoseLandmark.RIGHT_KNEE.value, mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "    return (d1 + d2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7a1373a3-efb0-485c-bcc2-6a3c6f9336af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sleeve_2(measurements):\n",
    "    d1 = get_distance(measurements, [mp_pose.PoseLandmark.LEFT_SHOULDER.value, mp_pose.PoseLandmark.LEFT_ELBOW.value, mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "    d2 = get_distance(measurements, [mp_pose.PoseLandmark.RIGHT_SHOULDER.value, mp_pose.PoseLandmark.RIGHT_ELBOW.value, mp_pose.PoseLandmark.RIGHT_WRIST.value])\n",
    "    print(d1, d2)\n",
    "    return (d1 + d2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "559a6151-e769-40a2-b4c5-904ceaee6d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3326740481924611"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_inseam(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1e520114-7bfe-422f-8cef-79e60b7a5f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1843055021994372 0.20354131061972133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19392340640957928"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_sleeve_2(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155868a-f23a-42ac-81d7-90b1e51a500f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb099fd-b88d-4877-8a76-e7f3cb58e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tensor = torch.mean(tensor_data[:, :, :], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1220d9fa-3ca6-47e0-85e4-ec644b82dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2450015-6220-46ae-abc7-a3ec406f1958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
