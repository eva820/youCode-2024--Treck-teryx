{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e6380b-dbea-4e94-9a91-032e6601dc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 17:08:17.569200: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-06 17:08:20.116696: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "# import csv\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "945212ac-8f6a-4d81-9c39-90f14e5fea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2a29481-114f-413f-9ec1-dd583218016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "    \n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         # image.flags.writable = False\n",
    "\n",
    "#         results = pose.process(image)\n",
    "\n",
    "#         # image.flags.writable = True\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "#         cv2.imshow('Mediapipe feed', image)\n",
    "        \n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dac1574-6c0e-43ae-911f-bb0987cc3fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({(15, 21), (16, 20), (18, 20), (3, 7), (14, 16), (23, 25), (28, 30), (11, 23), (27, 31), (6, 8), (15, 17), (24, 26), (16, 22), (4, 5), (5, 6), (29, 31), (12, 24), (23, 24), (0, 1), (9, 10), (1, 2), (0, 4), (11, 13), (30, 32), (28, 32), (15, 19), (16, 18), (25, 27), (26, 28), (12, 14), (17, 19), (2, 3), (11, 12), (27, 29), (13, 15)})\n"
     ]
    }
   ],
   "source": [
    "print(mp_pose.POSE_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4739a450-0604-4863-9309-1f68fe383d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({(15, 21), (16, 20), (18, 20), (3, 7), (14, 16), (23, 25), (28, 30), (11, 23), (27, 31), (6, 8), (15, 17), (24, 26), (16, 22), (4, 5), (5, 6), (29, 31), (12, 24), (23, 24), (0, 1), (9, 10), (1, 2), (0, 4), (11, 13), (30, 32), (28, 32), (15, 19), (16, 18), (25, 27), (26, 28), (12, 14), (17, 19), (2, 3), (11, 12), (27, 29), (13, 15)})\n"
     ]
    }
   ],
   "source": [
    "print(mp.solutions.pose.POSE_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d3a6bc-7d36-44c8-adc8-075081a97ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def body_in_frame(landmarks):\n",
    "    left = landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].y\n",
    "    right = landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].y\n",
    "    nose = landmarks[mp_pose.PoseLandmark.NOSE.value].y\n",
    "\n",
    "    # heel out of frame\n",
    "    if left > 0.95 or right > 0.95:\n",
    "        return False\n",
    "    # heel wayy to in frame\n",
    "    if left < 0 or right < 0 or nose < 0:\n",
    "        return False\n",
    "    if nose > 0.15:\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3930ebf0-6d14-4892-9f8c-ba265fffb18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1712448763.557816   54305 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1712448763.598070   54807 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 545.23.08), renderer: NVIDIA GeForce RTX 2060/PCIe/SSE2\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "captured_body = False\n",
    "quit = False\n",
    "measurements = []\n",
    "start = None\n",
    "image = None\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "    \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # variables to maintain continous stream of data\n",
    "            if not captured_body:\n",
    "                captured_body = True\n",
    "                start = time.time() \n",
    "\n",
    "            # if our body isn't in frame, restart\n",
    "            if not body_in_frame(landmarks):\n",
    "                captured_body = False\n",
    "                start = None\n",
    "                measurements.clear()\n",
    "                \n",
    "            # add landmarks to our current stuff\n",
    "            if captured_body:\n",
    "                measurements.append(landmarks)\n",
    "                \n",
    "                # quit when we have 3 seconds of data\n",
    "                if time.time() - start > 3:\n",
    "                    quit = True\n",
    "            \n",
    "        except:\n",
    "            captured_body = False\n",
    "            start = None\n",
    "            measurements.clear()\n",
    "\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        cv2.imshow('Mediapipe feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q') or quit:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ea94727-72ff-4879-90ce-34c7bafa13a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f50debb-be74-4f85-a482-4e40aa76855d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOSE : 0\n",
      "LEFT_EYE_INNER : 1\n",
      "LEFT_EYE : 2\n",
      "LEFT_EYE_OUTER : 3\n",
      "RIGHT_EYE_INNER : 4\n",
      "RIGHT_EYE : 5\n",
      "RIGHT_EYE_OUTER : 6\n",
      "LEFT_EAR : 7\n",
      "RIGHT_EAR : 8\n",
      "MOUTH_LEFT : 9\n",
      "MOUTH_RIGHT : 10\n",
      "LEFT_SHOULDER : 11\n",
      "RIGHT_SHOULDER : 12\n",
      "LEFT_ELBOW : 13\n",
      "RIGHT_ELBOW : 14\n",
      "LEFT_WRIST : 15\n",
      "RIGHT_WRIST : 16\n",
      "LEFT_PINKY : 17\n",
      "RIGHT_PINKY : 18\n",
      "LEFT_INDEX : 19\n",
      "RIGHT_INDEX : 20\n",
      "LEFT_THUMB : 21\n",
      "RIGHT_THUMB : 22\n",
      "LEFT_HIP : 23\n",
      "RIGHT_HIP : 24\n",
      "LEFT_KNEE : 25\n",
      "RIGHT_KNEE : 26\n",
      "LEFT_ANKLE : 27\n",
      "RIGHT_ANKLE : 28\n",
      "LEFT_HEEL : 29\n",
      "RIGHT_HEEL : 30\n",
      "LEFT_FOOT_INDEX : 31\n",
      "RIGHT_FOOT_INDEX : 32\n"
     ]
    }
   ],
   "source": [
    "for lndmrk in mp_pose.PoseLandmark:\n",
    "    print(lndmrk.name, \":\",  lndmrk.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52221312-c05d-44fe-8a10-9cc382bb9d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d98c39d1-61f4-4555-9020-1a3c5f7dffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_foot = landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].y\n",
    "# right_foot = landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].y\n",
    "# nose = landmarks[mp_pose.PoseLandmark.NOSE.value].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7add7097-ac9f-40c6-81df-eccc24a64e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(nose)\n",
    "# print(right_foot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b560a8d-c926-42df-87ec-897ac9fcea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((left_foot + right_foot)/2 - nose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f34d743e-fe42-46eb-b3d5-aef3290bee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('BGR Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e949f596-7d87-46f9-993f-d0618f245957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_avg, right_avg, nose_avg = [], [], []\n",
    "\n",
    "# for m in measurements:\n",
    "#     left_avg.append(m[mp_pose.PoseLandmark.LEFT_HEEL.value].y)\n",
    "#     right_avg.append(m[mp_pose.PoseLandmark.RIGHT_HEEL.value].y)\n",
    "#     nose_avg.append(m[mp_pose.PoseLandmark.NOSE.value].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d95fdc93-dce5-45de-8864-518cc0df3c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sum(left_avg)/len(left_avg) - sum(nose_avg)/len(nose_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18a40780-5ebc-43fc-aba6-7126732c4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_avg_x(measurements):\n",
    "    sum = 0    \n",
    "    for m in measurements:\n",
    "        sum += m.x\n",
    "    return sum / len(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67d15a22-3f64-4bb4-930c-cfac604e81f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_avg_y(measurements):\n",
    "    sum = 0    \n",
    "    for m in measurements:\n",
    "        sum += m.y\n",
    "    return sum / len(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16ebe364-7802-4981-a7f2-c7822bbe7647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# shldr, elb, wrst are lists of NormalizedLandmark (x,y,z)\n",
    "def find_sleeve_length(shldr, elb, wrst):\n",
    "    # print(type(shldr[0]))\n",
    "    shldr_x = find_avg_x(shldr)\n",
    "    shldr_y = find_avg_y(shldr)\n",
    "    elb_x = find_avg_x(elb)\n",
    "    elb_y = find_avg_x(elb)\n",
    "    wrst_x = find_avg_x(wrst)\n",
    "    wrst_y = find_avg_y(wrst)\n",
    "\n",
    "    d1 = math.sqrt((elb_x - shldr_x)**2 + (elb_y - shldr_y)**2)\n",
    "    d2 = math.sqrt((elb_x - wrst_x)**2 + (elb_y - wrst_y)**2)\n",
    "    \n",
    "    return d1 + d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "719999aa-5f82-4b4c-879b-9f940d3c7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sleeve(measurements):\n",
    "    # all these lists should be lists of x,y,z,visibility objects\n",
    "    r_shldr, r_elb, r_wrst = [], [], []\n",
    "    l_shldr, l_elb, l_wrst = [], [], [] \n",
    "\n",
    "    for m in measurements:\n",
    "        r_shldr.append(m[mp_pose.PoseLandmark.RIGHT_SHOULDER.value])\n",
    "        r_elb.append(m[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "        r_wrst.append(m[mp_pose.PoseLandmark.RIGHT_WRIST.value])\n",
    "        l_shldr.append(m[mp_pose.PoseLandmark.LEFT_SHOULDER.value])\n",
    "        l_elb.append(m[mp_pose.PoseLandmark.LEFT_ELBOW.value])\n",
    "        l_wrst.append(m[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "    \n",
    "    r_arm = find_sleeve_length(r_shldr, r_elb, r_wrst)\n",
    "    print(r_arm)\n",
    "    l_arm = find_sleeve_length(l_shldr, l_elb, l_wrst)\n",
    "    print(l_arm)\n",
    "    return (l_arm + r_arm) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d80a9-8c89-44f2-877d-603723061bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "298f0a39-e863-4434-bfaa-0cb434c0c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bottom(r_heel, l_heel):\n",
    "    l_heel_x = find_avg_x(l_heel)\n",
    "    l_heel_y = find_avg_y(l_heel)\n",
    "    r_heel_x = find_avg_x(r_heel)\n",
    "    r_heel_y = find_avg_y(r_heel)\n",
    "\n",
    "    avg_x = (l_heel_x + r_heel_x)/2\n",
    "    avg_y = (l_heel_y + r_heel_y)/2\n",
    "    return (avg_x, avg_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2123be60-2a51-4579-92a9-87637425a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top(nose):\n",
    "    nose_avg_x = find_avg_x(nose)\n",
    "    nose_avg_y = find_avg_y(nose)\n",
    "    return (nose_avg_x, nose_avg_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72c29cba-325d-4530-a8b6-a9c1a5e4ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_height(measurements):\n",
    "    r_heel, l_heel, nose = [], [], []\n",
    "    \n",
    "    for m in measurements:\n",
    "        r_heel.append(m[mp_pose.PoseLandmark.RIGHT_HEEL.value])\n",
    "        l_heel.append(m[mp_pose.PoseLandmark.LEFT_HEEL.value])\n",
    "        nose.append(m[mp_pose.PoseLandmark.NOSE.value])\n",
    "\n",
    "    # returns tuple of (avg_x_bottom, avg_y_bottom)\n",
    "    bot = find_bottom(r_heel, l_heel)\n",
    "    top = find_top(nose)\n",
    "    \n",
    "    return math.sqrt((bot[0] - top[0])**2 + (bot[1] - top[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c73da86d-426a-45b0-85b4-362e8fda908e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_pose.PoseLandmark.RIGHT_SHOULDER.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d2aab298-3fbc-4747-8994-c4dde91c3e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "22e74254-f5c0-433f-b1aa-b8b1f2940ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49440450188531315\n",
      "0.989862869307505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7421336855964091"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_sleeve(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "073d439e-f28e-4fa0-845e-d092b5f78648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7097005745531846"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_height(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd562cba-a38d-4e06-a453-5fc5073abac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5382372868833368\n",
      "1.1235459328775974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76.81518395448487"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(height - 5) / find_height(measurements) * find_sleeve(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559a6151-e769-40a2-b4c5-904ceaee6d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e520114-7bfe-422f-8cef-79e60b7a5f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
